{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f5d56bb-d078-414e-9783-d8306abb7d11",
   "metadata": {},
   "source": [
    "# 목차\n",
    "1. 파이프라인 개요 및 목표\n",
    "2. 데이터 로드 및 전처리\n",
    "3. 자동 특징 공학\n",
    "    - FeatureTools\n",
    "    - tsfresh\n",
    "    - tslearn\n",
    "4. 데이터 증강\n",
    "    - tsaug 활용\n",
    "    - 고급 데이터 증강 기법\n",
    "5. 이벤트 기반 특징 추출 및 증강\n",
    "6. 모델 하이퍼파라미터 튜닝\n",
    "    - Optuna 활용\n",
    "7. 다양한 모델 학습 및 이상치 탐지\n",
    "    - Autoencoder\n",
    "    - Variational Autoencoder(VAE)\n",
    "    - Generative Adversarial Networks (GANs)\n",
    "    - Deep Belief Networks (DBN)\n",
    "    - LSTM Autoencoder\n",
    "    - Transformer Autoencoder\n",
    "8. 앙상블 방법: Majority Voting\n",
    "9. 모델 평가\n",
    "10. 모델 해석 및 투명성 강화\n",
    "    - SHAP\n",
    "    - LIME\n",
    "11. 모델 최적화 및 경량화\n",
    "    - ONNX 변환\n",
    "    - TensorRT 최적화\n",
    "12. 파이프라인 자동화: Airflow활용\n",
    "13. 모델 배포 및 서비스화\n",
    "    - Flask를 사용한 REST API 구축\n",
    "14. 결론 및 추가 제안"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5132d1-1f68-4883-902f-57f599d70ee6",
   "metadata": {},
   "source": [
    "***\n",
    "## 1. 파이프라인 개요 및 목표\n",
    "\n",
    ">RiskPrediction 파이프라인은 시계열 데이터를 기반으로 이상치를 탐지하는 시스템을 구축하는 것을 목표로 함.\n",
    ">이 파이프라인은 데이터 로드부터 전처리, 특징 공학, 모델 학습, 이상치 탐지, 모델 해석, 최적화, 자동화, 배포에 이르는 전 과정을 포함\n",
    "\n",
    "- **데이터의 효율적 처리**: 대용량 시계열 데이터를 효과적으로 로드하고 전처리함\n",
    "- **자동 특징 추출**: 다양한 라이브러리(FeatureTools, tsfresh, tslearn)를 활용하여 데이터에서 유의미한 특징을 자동으로 추출함\n",
    "- **데이터 증강**: tsaug를 사용하여 데이터의 다양성을 높이고 모델의 일반화 능력을 향상 시킴\n",
    "- **다양한 모델 학습**: Autoencoder, VAE, GANs, DBN, LSTM_AE, Transformer_AE 등 여러 비지도 학습 모델을 학습시켜 이상치를 탐지함\n",
    "- **앙상블 방법 도입**: Majority Voting을 통해 여러 모델의 예측을 결합하여 최종 이상치 판별을 수행함\n",
    "- **모델 해석**: SHAP과 LIME을 사용하여 모델의 예측을 해석하고 투명성을 높임\n",
    "- **모델 최적화**: ONNX와 TensorRT를 활용하여 모델의 추론 속도를 최적화하고 경량화함\n",
    "- **파이프라인 자동화**: Airflow를 사용하여 데이터 처리, 모델 학습, 평가, 배포 등의 단계를 자동화함\n",
    "- **모델 배포**: Flask를 사용하여 학습된 모델을 REST API 형태로 배포하여 실시간 예측 시스템을 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb148b-24c6-4b73-bc02-daee7540a392",
   "metadata": {},
   "source": [
    "***\n",
    "## 2. 데이터 로드 및 전처리\n",
    "\n",
    "> 데이터 로드 및 전처리 단계에서는 시계열 데이터를 효율적으로 로드하고, 결측치를 처리하며, 필요한 전처리 작업을 수행함.\n",
    "> 기본적인 특징 공학을 통해 모델 학습에 필요한 기초적인 특징을 생성함\n",
    "\n",
    "### a. 필요한 라이브러리 설치\n",
    "\n",
    "```\n",
    "%pip install dask[complete] scikit-learn featuretools tsfresh tslearn tsaug optuna airflow flask shap lime pandas numpy matplotlib seaborn torch torchvision\n",
    "```\n",
    "\n",
    "### b. 데이터 로드 함수 구현\n",
    "\n",
    "> Dask를 사용하여 대용량 CSV 데이터를 효율적으로 로드하고, 필요한 전처리 작업을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a2167eb-bf44-40aa-bb7f-dd9011253c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import featuretools as ft\n",
    "import shap\n",
    "from lime import lime_tabular\n",
    "import tensorrt as trt\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tsfresh import extract_features\n",
    "# from tslearn.feature_extraction import FeatureRep\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "from tsaug import TimeWarp, Drift, AddNoise, Crop, Quantize, Reverse\n",
    "\n",
    "import optuna\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import silhouette_score, devies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(\n",
    "    level = logging.INFO,\n",
    "    format = '%(asctime)s [%(levelname)s] %(message)s',\n",
    "    handlers = [\n",
    "        logging.FileHandler(\"./Log/RiskPrediction.log\"),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def load_and_preprocess_data(data_file, sample_frace=0.1, window_size=100):\n",
    "    \"\"\"\n",
    "    데이터 로드 및 전처리 함수\n",
    "    - data_file: 데이터 파일 경로\n",
    "    - sample_frace: 샘플링 비율\n",
    "    - window_size: 윈도우 크기 (이벤트 기반 특징 추출용)\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        logger.info(\"Dask를 사용하여 데이터 로드 시작\")\n",
    "        with ProgressBar():\n",
    "            df = dd.read_csv(data_file, parse_dates=['VITALDATE', 'CHECKTIME'], assume_missing=True)\n",
    "            logger.info(f\"데이터 로드 완료: {df.shape[0].compute()} rows, {df.shape[1].compute()} columns\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"데이터 로드 중 오류 발생: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    try:\n",
    "        # 필요한 열만 선택\n",
    "        selected_columns = ['VITALDATE',\n",
    "                            'HEARTBEAT',\n",
    "                            'TEMPERATURE',\n",
    "                            'OUTSIDETEMPERATURE', \n",
    "                            'LATITUDE',\n",
    "                            'LONGITUDE',\n",
    "                            'SPEED',\n",
    "                            'X',\n",
    "                            'Y',\n",
    "                            'Z', \n",
    "                            'Event']  # 'Event' 컬럼 추가\n",
    "        df = df[selected_columns]\n",
    "\n",
    "        # 결측치 제거\n",
    "        logger.info(\"결측치 제거 시작\")\n",
    "        df = df.dropna()\n",
    "        logger.info(f\"결측치 제거 완료: {df.shape[0].compute()} rows 남음\")\n",
    "\n",
    "        # 데이터 타입 변환 (float형으로)\n",
    "        numeric_cols = ['HEARTBEAT',\n",
    "                        'TEMPERATURE',\n",
    "                        'OUTSIDETEMPERATURE', \n",
    "                        'LATITUDE',\n",
    "                        'LONGITUDE',\n",
    "                        'SPEED',\n",
    "                        'X', \n",
    "                        'Y', \n",
    "                        'Z']\n",
    "        df[numeric_cols] = df[numeric_cols].astype(float)\n",
    "\n",
    "        # 정규화 (표준화)\n",
    "        logger.info(\"데이터 정규화 시작\")\n",
    "        scaler = StandardScaler()\n",
    "        df[numeric_cols] = dd.from_array(scaler.fit_transform(df[numeric_cols].compute()), columns=numeric_cols)\n",
    "        logger.info(\"데이터 정규화 완료\")\n",
    "\n",
    "        # 기본 특징 공학\n",
    "        logger.info(\"기본 특징 공학 시작\")\n",
    "\n",
    "        # 심박수에서 RR 간격 추정 (초 단위)\n",
    "        df['RR_interval'] = 60 / df['HEARTBEAT']\n",
    "\n",
    "        # RR_interval의 결측치 제거\n",
    "        df = df.dropna(subset=['RR_interval'])\n",
    "\n",
    "        # 시간순으로 정렬\n",
    "        df = df.map_partitions(lambda partition: partition.sort_values('VITALDATE'))\n",
    "\n",
    "        # NN 간격 계산 (연속하는 RR_interval 간의 차이)\n",
    "        df['NN_interval'] = df['RR_interval'].diff()\n",
    "\n",
    "        # SDNN (NN_interval의 표준편차)\n",
    "        SDNN = df['NN_interval'].std().compute()\n",
    "        logger.info(f\"SDNN: {SDNN}\")\n",
    "\n",
    "        # RMSSD (NN_interval의 제곱 평균 제곱근)\n",
    "        RMSSD = np.sqrt((df['NN_interval'] ** 2).mean().compute())\n",
    "        logger.info(f\"RMSSD: {RMSSD}\")\n",
    "\n",
    "        # 자이로스코프 데이터에서 회전 속도 변화 측정\n",
    "        df['Gyro_magnitude'] = np.sqrt(df['X'] ** 2 + df['Y'] ** 2 + df['Z'] ** 2)\n",
    "\n",
    "        # 회전 속도 변화의 변동성 측정 (Rolling Standard Deviation)\n",
    "        df['Gyro_std'] = df['Gyro_magnitude'].rolling(window=window_size).std()\n",
    "\n",
    "        # 온도 차이 계산\n",
    "        df['Temperature_difference'] = df['TEMPERATURE'] - df['OUTSIDETEMPERATURE']\n",
    "\n",
    "        # 시간 기반 특징 생성\n",
    "        # 시간대 (시간)\n",
    "        df['Hour'] = df['VITALDATE'].dt.hour\n",
    "\n",
    "        # 작업 시작 후 경과 시간 (첫 번째 기록 시각으로부터의 시간 차이)\n",
    "        start_time = df['VITALDATE'].min().compute()\n",
    "        df['Time_since_start'] = (df['VITALDATE'] - start_time).dt.total_seconds() / 3600  # 시간 단위\n",
    "\n",
    "        logger.info(\"기본 특징 공학 완료\")\n",
    "\n",
    "        return df, scaler, numeric_cols, window_size\n",
    "    except Exception as e:\n",
    "        logger.error(f\"데이터 전처리 중 오류 발생: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530ab6ef-8347-4f9e-b935-0229f9569bd6",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "1. **데이터로드**: Dask를 사용하여 대용량 CSV 데이터를 효율적으로 로드\n",
    "2. **필요한 열 선택**: 분석에 필요한 열만 선택하여 메모리 사용을 최적화\n",
    "3. **결측치 제거**: 결측치를 제거하여 데이터의 품질을 향상 시킴\n",
    "4. **데이터 타입 변환 및 정규화**: 수치형 데이터를 float으로 변환하고, StandardScaler를 사용하여 정규화함\n",
    "5. **기본 특징 공학**:\n",
    "    - **RR 간격 계산**: 심박수에서 RR 간격을 추정\n",
    "    - **NN 간격 및 SDNN, RMSSD 계산**: 심박수 변동성을 측정하는 지표를 계산\n",
    "    - **자이로스코프 데이터 처리**: 자이로스코프 데이터를 기반으로 회전 속도 변화의 변동성을 측정\n",
    "    - **온도 차이 계산**: 내부 및 외부 온도 차이를 계산하여 환경 변화의 영향을 파악함\n",
    "    - **시간 기반 특징 생성**: 시간대 및 작업 시작 후 경과 시간을 계산하여 시간에 따른 패턴 변화를 포착함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896b57b1-bcf8-4566-be55-e5780a83e58a",
   "metadata": {},
   "source": [
    "***\n",
    "## 3. 자동 특징 공학\n",
    "\n",
    "> 자동 특징 공학은 데이터에서 유의미한 특징을 자동으로 추출하는 과정.\n",
    "> 이를 통해 도메인 전문가의 개입 없이도 모델의 성능을 향상시킬 수 있음.\n",
    "> 여기서는 **FeatureTools, tsfresh, tslearn 을 활용하여 다양한 특징을 추출함\n",
    "\n",
    "### a. FeatureTools 활용\n",
    "\n",
    "> **FeatureTools는 자동화된 특징 공학을 지원하는 라이브러리로, 복잡한 데이터 구조에서도 효율적으로 특징을 생성할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb94c2e1-733a-4e25-821e-8c2a1ebe0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_feature_engineering(df):\n",
    "    \"\"\"\n",
    "    FeatureTools를 사용하여 자동 특징 공학을 수행함\n",
    "    - df: pandas DataFrame\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"FeatureTools를 사용한 자동 특징 공학 시작\")\n",
    "\n",
    "        # EntitySet 생성\n",
    "        es = ft.EntitySet(id=\"risk_prediction\")\n",
    "\n",
    "        # 인덱스 설정\n",
    "        df = df.reset_index()\n",
    "        es = es.add_dataframe(\n",
    "            dataframe_name = \"data\",\n",
    "            dataframe = df,\n",
    "            index = \"index\",\n",
    "            time_index = \"VITALDATE\"\n",
    "        )\n",
    "\n",
    "        # 트랜스폼 프리미티브 설정\n",
    "        trans_primitives = [\"add\", \"multiply\", \"subtract\", \"divide\", \"abs\", \"sqrt\"]\n",
    "\n",
    "        # 특징 생성\n",
    "        feature_matrix_ft, feature_defs_ft = ft.dfs(\n",
    "            entityset = es,\n",
    "            target_dataframe_name = \"data\",\n",
    "            trans_primitives = trans_primitives,\n",
    "            max_depth = 2,\n",
    "            features_only = False,\n",
    "            verbose = True\n",
    "        )\n",
    "\n",
    "        logger.info(f\"FeatureTools를 사용한 자동 특징 공학 완료: 생성된 특징 수 {feature_matrix_ft.shape[1]}\")\n",
    "        return feature_matrix_ft\n",
    "    except Exception as e:\n",
    "        logger.error(f\"FeatureTools를 사용한 자동 특징 공학 중 오류 발생: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daa7fe4-8f90-4f77-9ce9-b2a71ea84f53",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **EntitySet 생성**: 데이터프레임을 FeatureTools의 EntitySet에 추가하여 특징 공학을 수행할 수 있는 환경을 조성함\n",
    "- **트랜스폼 프리미티브 설정**: 기본적인 수학 연산을 통해 새로운 특징을 생성함\n",
    "- **특징 생성**: `ft.dfs` 함수를 사용하여 지정된 트랜스폼 프리미티브를 기반으로 자동으로 특징을 생성함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5c2744-9933-4dec-af4f-eaa091e680b3",
   "metadata": {},
   "source": [
    "### b.tsfresh 활용\n",
    "\n",
    "> **tsfresh**는 시계열 데이터에서 유의미한 특징을 자동으로 추출하는 라이브러리로, 다양한 시계열 통계적 특징을 제공함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de2a1271-d6a8-4c96-b14b-adc268ba66d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tsfresh_features(df):\n",
    "    \"\"\"\n",
    "    tsfresh를 사용하여 시계열 데이터의 특징을 추출함\n",
    "    - df: pandas DataFrame\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"tsfresh를 사용한 특징 추출 시작\")\n",
    "\n",
    "        # 시계열 데이터의 포맷 변환\n",
    "        ts_data = df[['index', 'VITALDATE', 'HEARTBEAT', 'TEMPERATURE', 'OUTSIDETEMPERATURE', \n",
    "                     'LATITUDE', 'LONGITUDE', 'SPEED', 'X', 'Y', 'Z']]\n",
    "\n",
    "        # 특징 추출\n",
    "        feature_matrix_tsfresh = extract_features(ts_data, column_id = \"index\", column_sort = \"VITALDATE\")\n",
    "\n",
    "        logger.info(f\"tsfresh를 사용한 특징 추출 완료: 생성된 특징 수 {feature_matrix_tsfresh.shape[1]}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"tsfresh를 사용한 특징 추출 중 오류 발생: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be947ce-6f98-4099-bb90-aa47b8236262",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **시계열 데이터 포맷 변환**: tsfresh는 특정 포맷의 시계열 데이터를 필요로 하므로, 데이터프레임을 적절히 변환함\n",
    "- **특징 추출**: `extract_features` 함수를 사용하여 다양한 시계열 통계적 특징을 자동으로 추출함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce99021-74e3-4ef1-8c32-d4f65db83445",
   "metadata": {},
   "source": [
    "### c. tslearn 활용\n",
    "\n",
    "> **tslearn**은 시계열 데이터 분석을 위한 다양한 도구를 제공하는 라이브러리로, 시계열 데이터의 패턴을 효과적으로 추출할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6dee057-c846-4655-8d75-bb1f115976ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tslearn_features(X, n_features=10):\n",
    "    \"\"\"\n",
    "    tslearn을 사용하여 시계열 데이터의 특징을 추출함\n",
    "    - X: 입력 데이터 (numpy array), shape (samples, features)\n",
    "    - n_features: 추출할 특징 수\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"tslearn을 사용한 특징 추출 시작\")\n",
    "\n",
    "        # 시계열 스케일링\n",
    "        scaler = TimeSeriesScalerMeanVariance()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        # FeatureRep를 사용한 특징 추출 (예: Fast Fourier Transform 등)\n",
    "        feature_rep = FeatureRep(n_coefficients=n_features, random_state=42)\n",
    "        X_tslearn = feature_rep.fit_transform(X_scaled)\n",
    "\n",
    "        logger.info(f\"tslearn을 사용한 특징 추출 완료: 추출된 특징 수 {X_tslearn.shape[1]}\")\n",
    "        return X_tslearn\n",
    "    except Exception as e:\n",
    "        logger.error(f\"tslearn을 사용한 특징 추출 중 오류 발생: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18a48d7-81ce-410b-a9e2-90e26e781057",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **시계열 스케일링**: 시계열 데이터를 평균과 분산을 기준으로 정규화하여 특징 추출의 효율성을 높임\n",
    "- **FeatureRep 활용**: 다양한 시계열 변환 기법(Fast Fourier Transform 등)을 통해 특징을 추출함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22825d92-2b23-49e3-a572-4cbe75e93ad1",
   "metadata": {},
   "source": [
    "***\n",
    "## 4. 데이터 증강\n",
    "\n",
    "> 데이터 증강은 모델의 일반화 능력을 향상시키기 위해 데이터의 다양성을 높이는 기법.   \n",
    "> 시계열 데이터의 경우, 다양한 증강 기법을 통해 패턴의 변화를 생성할 수 있음   \n",
    "> 여기서는 **tsauf** 라이브러리를 활용하여 고급 데이터 증강을 수행   \n",
    "> **Time Warping, Window Slicing, Permutation, Magnitude Scaling, Jittering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d19fc90-d482-4789-837e-d9aceeeba82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_data_augmentation(X, n_augment=2):\n",
    "    \"\"\"\n",
    "    고급 시계열 데이터 증강 함수\n",
    "    - X: 입력 데이터 (numpy array), shape (samples, features)\n",
    "    - n_augment: 각 샘플당 증강할 데이터 수\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"고급 시계열 데이터 증강 시작: n_augment = {n_augment}\")\n",
    "\n",
    "        # 다양한 증강 기법 정의\n",
    "        augmenter = (\n",
    "            TimeWarp(n_speed_change=2) * 2 +\n",
    "            Drift(scale=0.05) +\n",
    "            Scale(scale=(0.95, 1.05)) +\n",
    "            AddNoise(scale=0.02) +\n",
    "            Shuffle(n_shuffle=2) +\n",
    "            Stretch(scale=(0.8, 1.2)) +\n",
    "            Quantize(n_levels=8) + \n",
    "            Reverse()\n",
    "        )\n",
    "\n",
    "        # 증강 데이터 생성\n",
    "        augmented_data = []\n",
    "        for _ in range(n_augment):\n",
    "            augmented = augmenter.augment(X)\n",
    "            augmented_data.append(augmented)\n",
    "        X_augmented = np.concatenate(augmented_data, axis=0)\n",
    "\n",
    "        logger.info(f\"고급 시계열 데이터 증강 완료: 증강된 데이터 수 {X_augmented.shape[0]}\")\n",
    "        return X_augmented\n",
    "    except Exception as e:\n",
    "        logger.error(f\"고급 시계열 데이터 증강 중 오류 발생: {e}\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b585831c-673f-4c8a-94b1-8b5d29f2d479",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **증강 기법 정의**:\n",
    "    - **Time Warping**: 시계열 의 시간 축을 변형하여 패턴의 변화를 만듦\n",
    "    - **Drift**: 데이터의 기울기를 변경하여 다양한 변화를 만듦\n",
    "    - **Scale**: 데이터의 크기를 변경하여 다양한 규모의 패턴을 만듦\n",
    "    - **AddNoise**: 데이터에 노이즈를 추가하여 모델의 견고성을 높임\n",
    "    - **Shuffle**: 시계열 데이터의 일부를 섞어 새로운 패턴을 만듦\n",
    "    - **Stretch**: 시계열의 길이를 늘이거나 줄여 패턴의 변화를 만듦\n",
    "    - **Quantize**: 시계열 데이터를 양자화하여 패턴의 단순화를 유도함\n",
    "    - **Reverse**: 시계열 데이터를 반전시켜 패턴의 방향성을 변화시킴\n",
    "- **증강 데이터 생성**: 지정된 횟수만큼 데이터를 증강하여 원본 데이터의 다양성을 높임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9369b2c-fe83-4342-a537-48a8592dc2c3",
   "metadata": {},
   "source": [
    "***\n",
    "## 5. 이벤트 기반 특징 추출 및 증강\n",
    "\n",
    "> 원본 데이터가 이벤트 기반성이 강한 경우, 이벤트의 발생 빈도, 간격, 지속 시간 등의 특징을 추출하고 이를 증강에 반영하는 것이 중요   \n",
    "> 이를 통해 모델이 이벤트의 패턴을 효과적으로 학습할 수 있음\n",
    "\n",
    "### a. 이벤트 기반 특징 추출\n",
    "\n",
    "> 이벤트의 발생 패턴을 분석하기 위해 이벤트 기반 특징을 추출함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99440430-bc68-4ac0-a9da-e434bd7e09c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_event_features(df, event_column='Event'):\n",
    "    \"\"\"\n",
    "    이벤트 기반 데이터의 특징을 추출함\n",
    "    - df: pandas DataFrame\n",
    "    - event_column: 이벤트를 나타내는 컬럼 이름\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"이벤트 기반 특징 추출 시작\")\n",
    "\n",
    "        # 이벤트 발생 여부를 나타내는 이진 변수 생성\n",
    "        df['event_flag'] = df[event_column].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "        # 이벤트 발생 간격 계산\n",
    "        df['event_diff'] = df['event_flag'].diff().fillna(0)\n",
    "\n",
    "        # 이벤트 간격의 평균, 표준편차\n",
    "        event_intervals = df['event_diff'].replace(0, np.nan).dropna()\n",
    "        df['event_interval_mean'] = event_intervals.mean()\n",
    "        df['event_interval_std'] = event_intervals.std()\n",
    "\n",
    "        # 이벤트 지속 시간 계산 (rolling window)\n",
    "        df['event_duration'] = df['event_flag'].rolling(window=window_size).sum()\n",
    "\n",
    "        logger.info(\"이벤트 기반 특징 추출 완료\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"이벤트 기반 특징 추출 중 오류 발생: {e}\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8f8acb-f536-47f5-bc89-f7d17eacf584",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **event_flag**: 특정 시점에 이벤트가 발생했는지 여부를 이진 변수로 나타냄\n",
    "- **event_diff**: 이벤트 발생 간의 간격을 계산하여 이벤트 간의 변화 패턴을 파악함\n",
    "- **event_interval_mean, event_interval_std**: 이벤트 발생 간격의 평균과 표준편차를 계산하여 이벤트의 빈도 및 변동성을 측정함\n",
    "- **event_duration**: 일정 윈도우 내 이벤트의 지속 시간을 계산하여 이벤트의 지속성을 파악함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576467d4-1241-4395-a924-f34c0f407395",
   "metadata": {},
   "source": [
    "### b. 이벤트 기반 데이터 증강\n",
    "\n",
    "> 이벤트 기반 특징을 유지하면서 데이터를 증강함.\n",
    "> 예를 들어, 이벤트의 발생 시점을 변경하거나, 이벤트의 지속 시간을 변형시킬 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0d12a25-5192-4709-aa9c-21c13554c10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_based_data_augmentation(df, n_augment=2):\n",
    "    \"\"\"\n",
    "    이벤트 기반 시계열 데이터 증강 함수\n",
    "    - df: pandas DataFrame\n",
    "    - n_augment: 각 샘플당 증강할 데이터 수\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"이벤트 기반 시계열 데이터 증강 시작: n_augment = {n_augment}\")\n",
    "\n",
    "        augmented_dfs = []\n",
    "        for _ in range(n_augment):\n",
    "            df_aug = df.copy()\n",
    "\n",
    "            # 이벤트 발생 시점 랜덤 변경\n",
    "            event_shift = np.random.randint(-5, 6)  # 예: -5에서 +5 샘플 이동\n",
    "            df_aug['event_flag'] = df_aug['event_flag'].shift(event_shift).fillna(0)\n",
    "\n",
    "            # 이벤트 지속 시간 변형\n",
    "            duration_scaling = np.random.uniform(0.8, 1.2)\n",
    "            df_aug['event_duration'] = (df_aug['event_duration'] * duration_scaling).astype(int)\n",
    "\n",
    "            augmented_dfs.append(df_aug)\n",
    "\n",
    "        df_augmented = pd.concat(augmented_dfs, ignore_index=True)\n",
    "        logger.info(f\"이벤트 기반 시계열 데이터 증강 완료: 증강된 데이터 수 {df_augmented.shape[0]}\")\n",
    "        return df_augmented\n",
    "    except Exception as e:\n",
    "        logger.info(f\"이벤트 기반 시계열 데이터 증강 중 오류 발생: {e}\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c106a04-37e7-4856-a757-1e8faf5d5fb4",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **이벤트 시점 변경**: 이벤트 발생 시점을 랜덤하게 변경하여 다양한 이벤트 패턴을 생성함\n",
    "- **이벤트 지속 시간 변형**: 이벤트의 지속 시간을 변형시켜 모델이 다양한 이벤트 지속성을 학습할 수 있도록 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8ee3ad-16a6-4c50-9c0b-5878fd209974",
   "metadata": {},
   "source": [
    "***\n",
    "## 6. 모델 하이퍼파라미터 튜닝\n",
    "\n",
    "> 모델의 성능을 최적화하기 위해 하이퍼파라미터 튜닝을 수행함.\n",
    "> **Optuna**를 활용하여 자동화된 하이퍼파라미터 최적화를 진행함\n",
    "\n",
    "### a. Optuna 활용\n",
    "\n",
    "> **Optuna**는 효율적인 하이퍼파라미터 최적화를 지원하는 라이브러리로, 다양한 최적화 알고리즘을 제공함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b30451ab-fe70-46d2-a530-dba84b9e3747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_iso(trial, X):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    contamination = trial.suggest_float('contamination', 0.001, 0.002)\n",
    "    max_samples = trial.suggest_categorical('max_samples', ['auto', 0.5, 0.75, 1.0])\n",
    "\n",
    "    model = IsolationForest(n_estimators = n_estimators,\n",
    "                            contamination = contamination,\n",
    "                            max_samples = max_samples,\n",
    "                            random_state = 42)\n",
    "    model.fit(X)\n",
    "    labels = pd.Series(model.predict(X)).map({1: 0, -1: 1})  # 0: 정상, 1: 이상치\n",
    "    if len(set(labels)) > 1:\n",
    "        score = silhouette_score(X, labels)\n",
    "    else:\n",
    "        score = -1  # 무의미한 클러스터링\n",
    "    return score\n",
    "\n",
    "def objective_lof(trial, X):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 10, 50)\n",
    "    contamination = trial.suggest_float('contamination', 0.001, 0.02)\n",
    "\n",
    "    model = LocalOutlierFactor(n_neighbors = n_neighbors,\n",
    "                               contamination = comtamination,\n",
    "                               novelty = True)\n",
    "\n",
    "    model.fit(X)\n",
    "    labels = pd.Series(model.predict(X)).map({1: 0, -1: 1})\n",
    "    if len(set(labels)) > 1:\n",
    "        score = silhouette_score(X, labels)\n",
    "    else:\n",
    "        score = -1\n",
    "    return score\n",
    "\n",
    "def objective_svm(trial, X):\n",
    "    kernel = trial.suggest_categorical('kernel', ['rbf', 'linear', 'poly'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "    nu = trial.suggest_float('nu', 0.001, 0.02)\n",
    "\n",
    "    model = OneClassSVM(kernel = kernel,\n",
    "                        gamma = gamma,\n",
    "                        nu = nu)\n",
    "    model.fit(X)\n",
    "    labels = pd.Series(model.predict(X)).map({1: 0, -1: 1})\n",
    "    if len(set(labels)) > 1:\n",
    "        score = silhouette_score(X, labels)\n",
    "    else:\n",
    "        score = -1\n",
    "    return score\n",
    "\n",
    "def tune_model(objective, X, n_trials=50):\n",
    "    study = optuna.create_study(direction = 'maximize')\n",
    "    study.optimize(lambda trial: objective(trial, X), n_trials = n_trials)\n",
    "    logger.info(f\"{objective.__name__} 최적화 완료: Best Params: {study.best_params}, Best Silhouette Score: {study.best_value}\")\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a961a01-fa97-4fa8-a3a6-773d172efcd0",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **objective_iso**: Isolation Forest 모델의 하이퍼파라미터(n_estimators, contamination, max_samples)를 최적화하여 최적의 Silhouette Score를 도출함\n",
    "- **objective_lof**: Local Outlier Factor 모델의 하이퍼파라미터(n_neighbors, contamination)를 최적화함\n",
    "- **objective_svm**: One-Class SVM 모델의 하이퍼파라미터(kernel, gamma, nu)를 최적화함\n",
    "- **tune_model**: 주어진 objective 함수를 기반으로 Optuna를 사용하여 하이퍼파라미터 최적화를 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e32af8-e761-449c-9bdc-6b5e2a1e4303",
   "metadata": {},
   "source": [
    "## 7. 다양한 모델 학습 및 이상치 탐지\n",
    "\n",
    "> 이상치 탐지를 위해 다양한 비지도 학습 모델을 학습시키고, 각 모델의 예측 결과를 기반으로 이상치를 탐지.   \n",
    "> 여기서는 **Autoencoder, Variational Autoencoder (VAE), Generative Adversarial Networks (GANs), Deep Belief Networks (DBN), LSTM Autoencoder, Transformer Autoencoder** 등을 다룸\n",
    "\n",
    "### a. Autoencoder\n",
    "\n",
    "> Autoencoder는 입력 데이터를 압축하여 잠재 공간(latent space)에 표현한 후, 이를 다시 복원하는 신경망\n",
    "> 재구성 오류를 기반으로 이상치를 탐지할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "717a4006-1323-429b-8db1-ef330c5c839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim = 32):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # 인코더\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, latent_dim),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # 디코더\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed\n",
    "\n",
    "def train_autoencoder_model(X_train, X_val, input_dim, latent_dim=32, num_epochs=50, batch_size=1024):\n",
    "    \"\"\"\n",
    "    Autoencoder 모델 학습 함수\n",
    "    - X_train: 학습 데이터 (numpy array)\n",
    "    - X_val: 검증 데이터 (numpy array)\n",
    "    - input_dim: 입력 특징의 차원 수\n",
    "    - latent_dim: 잠재 공간의 차원 수\n",
    "    - num_epochs: 학습 에폭 수\n",
    "    - batch_size: 배치 크기\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"Autoencoder 모델 학습 시작\")\n",
    "\n",
    "        # 텐서 변환\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "\n",
    "        # DataLoader 생성\n",
    "        train_dataset = TensorDataset(X_train_tensor)\n",
    "        val_dataset = TensorDataset(X_val_tensor)\n",
    "        train_loader = DataLoader(train_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=0)\n",
    "        val_loader = DataLoader(val_dataset,\n",
    "                                batch_size=batch_size, \n",
    "                                shuffle=False,\n",
    "                                num_workers=0)\n",
    "\n",
    "        # 모델 초기화\n",
    "        autoencoder = Autoencoder(input_dim = input_dim, latent_dim = latent_dim).to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(autoencoder.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "        best_val_loss = np.inf\n",
    "        for epoch in range(num_epochs):\n",
    "            autoencoder.train()\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for data in train_loader:\n",
    "                inputs = data[0].to(device)\n",
    "                outputs = autoencoder(inputs)\n",
    "                loss = criterion(outputs, inputs)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "            epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "            # 검증\n",
    "            autoencoder.eval()\n",
    "            running_val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    inputs = data[0].to(device)\n",
    "                    outputs = autoencoder(inputs)\n",
    "                    loss = criterion(outputs, inputs)\n",
    "                    running_val_loss += loss.item()\n",
    "            epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "\n",
    "            logger.info(f\"Epoch [{epoch + 1} / {num_epochs}], Train_Loss: {epoch_train_loss: .6f}, Val_Loss: {epoch_val_loss: .6f}\")\n",
    "\n",
    "            # 최적 모델 저장\n",
    "            if epoch_val_loss < best_val_loss:\n",
    "                best_val_loss = epoch_val_loss\n",
    "                torch().save(autoencoder.state_dict(), './Models/autoencoder.pth')\n",
    "                logger.info(f\"최적 Autoencoder 모델 저장 (Epoch {epoch + 1})\")\n",
    "\n",
    "        # 학습 완료 후 최적 모델 로드\n",
    "        autoencoder.load_state_dict(torch.load('./Models/autoencoder.pth'))\n",
    "        autoencoder.eval()\n",
    "        logger.info(\"Autoencoder 모델 학습 완료 및 최적 모델 로드\")\n",
    "\n",
    "        # 재구성 오류 계산\n",
    "        reconstruction_errors = []\n",
    "        data_loader_full = DataLoader(TensorDataset(torch.tensor(X_full, dtype=torch.float32)),\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=False,\n",
    "                                      num_workers=0)\n",
    "        logger.info(\"Autoencoder를 사용한 재구성 오류 계산 시작\")\n",
    "        for data in tqdm(data_loader_full, desc=\"Autoencoder Reconstruction Error\"):\n",
    "            inputs = data[0].to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = autoencoder(inputs)\n",
    "                loss = torch.mean((outputs - inputs) ** 2, dim=1)  # 샘플별 MSE\n",
    "                reconstruction_errors.extend(loss.cpu().numpy())\n",
    "\n",
    "        # 재구성 오류 기반 이상치 탐지\n",
    "        threshold = np.percentile(reconstruction_errors, 99.5)  # 상위 0.5%를 이상치로 간주\n",
    "        anomalies = np.array(reconstruction_errors) > threshold\n",
    "        logger.info(\"Autoencoder 기반 이상치 탐지 완료\")\n",
    "\n",
    "        return anomalies, reconstruction_errors\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Autoencoder 모델 학습 중 오류 발생: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c52ab0b-3720-4338-afaa-20117afce0d7",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **Autoencoder 클래스**: 인코더와 디코더로 구성된 단순한 구조의 Autoencoder를 정의\n",
    "- **train_autoencoder_model 함수**: Autoencoder 모델을 학습시키고, 검증 데이터를 기반으로 최적의 모델을 저장함. 학습이 완료된 후, 전체 데이터에 대한 재구성 오류를 계산하여 이상치를 탐지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc60874-6aa6-4fb0-95ad-b7f29571835a",
   "metadata": {},
   "source": [
    "### b.Variational Autoencoder (VAE)\n",
    "\n",
    "> VAE는 Autoencoder의 확장으로, 잠재 공간의 분포를 정규화하여 생성 모델의 특성을 가짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57e8c3cb-922e-4831-8e54-f97df8c42550",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=32):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # 인코더\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(64, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(64, latent_dim)\n",
    "\n",
    "        # 디코더\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        def encoder(self, x):\n",
    "            h = self.encoder(x)\n",
    "            mu = self.fc_mu(h)\n",
    "            logvar = self.fc_logvar(h)\n",
    "            return mu, logvar\n",
    "\n",
    "        def reparameterize(self, mu, logvar):\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mu + eps * std\n",
    "\n",
    "        def decode(self, z):\n",
    "            return self.decoder(z)\n",
    "\n",
    "        def forward(self, x):\n",
    "            mu, logvar = self.encoder(x)\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            reconstructed = self.decode(z)\n",
    "            return reconstructed, mu, logvar\n",
    "\n",
    "def train_vae_model(X_train, X_val, input_dim, latent_dim=32, num_epochs=50, batch_size=1024):\n",
    "    \"\"\"\n",
    "    VAE 모델 학습 함수\n",
    "    - X_train: 학습 데이터 (numpy array)\n",
    "    - X_val: 검증 데이터 (numpy array)\n",
    "    - input_dim: 입력 특징의 차원 수\n",
    "    - latent_dim: 잠재 공간의 차원 수\n",
    "    - num_epochs: 학습 에폭 수\n",
    "    - batch_size: 배치 크기\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"VAE 모델 학습 시작\")\n",
    "\n",
    "        # 텐서 변환\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "\n",
    "        # DataLoader 생성\n",
    "        train_dataset = TensorDataset(X_train_tensor)\n",
    "        val_dataset = TensorDataset(X_val_tensor)\n",
    "        train_loader = DataLoader(train_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=0)\n",
    "        val_loader = DataLoader(val_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                num_workers=0)\n",
    "\n",
    "        # 모델 초기화\n",
    "        vae = VAE(input_dim=input_dim, latent_dim=latent_dim).to(device)\n",
    "        criterion = nn.MSELoss(reduction='sum')\n",
    "        optimizer = optim.Adam(vae.parameters(),\n",
    "                               lr=1e-3,\n",
    "                               weight_decay=1e-5)\n",
    "\n",
    "        best_val_loss = np.inf\n",
    "        for epoch in range(num_epochs):\n",
    "            vae.train()\n",
    "            running_loss = 0.0\n",
    "            for data in train_loader:\n",
    "                inputs = data[0].to(device)\n",
    "                reconstructed, mu, logvar = vae(inputs)\n",
    "                recon_loss = criterion(reconstructed, inputs)\n",
    "                kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "                loss = recon_loss + kl_loss\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "            epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "            # 검증\n",
    "            vae.eval()\n",
    "            running_val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    inputs = data[0].to(device)\n",
    "                    reconstructed, mu, logvar = vae(inputs)\n",
    "                    recon_loss = criterion(reconstructed, inputs)\n",
    "                    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "                    loss = recon_loss + kl_loss\n",
    "                    running_val_loss += loss.item()\n",
    "            epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "\n",
    "            logger.info(f\"Epoch [{epoch + 1} / {num_epochs}], Train_Loss: {epoch_train_loss:.6f}, Val_Loss: {epoch_val_loss:.6f}\")\n",
    "\n",
    "            # 최적 모델 저장\n",
    "            if epoch_val_loss < best_val_loss:\n",
    "                best_val_loss = epoch_val_loss\n",
    "                torch.save(vae.state_dict(), './Modles/vae.pth')\n",
    "                logger.info(f\"최적 VAE 모델 저장 (Epoch {epoch + 1})\")\n",
    "\n",
    "        # 학습 완료 후 최적 모델 로드\n",
    "        vae.load_state_dict(torch.load('./Models/vae.pth'))\n",
    "        vae.eval()\n",
    "        logger.info(\"VAE 모델 학습 완료 및 최적 모델 로드\")\n",
    "\n",
    "        # 재구성 오류 계산\n",
    "        reconstruction_errors = []\n",
    "        data_loader_full = DataLoader(TensorDataset(torch.tensor(X_full, dtype=torch.float32)),\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=False,\n",
    "                                      num_worker=0)\n",
    "        logger.info(\"VAE를 사용한 재구성 오류 계산 시작\")\n",
    "        for data in tqdm(data_loader_full, desc=\"VAE Reconstruction Error\"):\n",
    "            inputs = data[0].to(device)\n",
    "            with torch.no_grad():\n",
    "                reconstructed, mu, logvar = vae(inputs)\n",
    "                loss = torch.mean((reconstructed - inputs) ** 2, dim=1)  # 샘플별 MSE\n",
    "                reconstruction_errors.extend(loss.cpu().numpy())\n",
    "\n",
    "        # 재구성 오류 기반 이상치 탐지\n",
    "        threshold = np.percentile(reconstruction_errors, 99.5)  # 상위 0.5%를 이상치로 간주\n",
    "        anomalies = np.array(reconstruction_errors) > threshold\n",
    "        logger.info(\"VAE 기반 이상치 탐지 완료\")\n",
    "\n",
    "        return anomalies, reconstruction_errors\n",
    "    except Exception as e:\n",
    "        logger.error(f\"VAE 모델 학습 중 오류 발생: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef096a78-f837-4d87-8f98-af4be4773b05",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **VAE 클래스**: 인코더, 디코더, 그리고 잠재 공간의 평균과 로그 분산을 계산하는 레이어로 구성\n",
    "- **train_vae_model 함수**: VAE 모델을 학습시키고, 검증 데이터를 기반으로 최적의 모델을 저장. 학습 완료 후, 전체 데이터에 대한 재구성 오률를 계산하여 이상치를 탐지함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1928c87e-0618-4921-b94c-162c957a1258",
   "metadata": {},
   "source": [
    "### c. Generative Adversarial Networks (GANs)\n",
    "\n",
    "> GANs는 생성자(Generator)와 판별자(Discriminator)로 구성된 모델로, 데이터의 분포를 학습하여 새로운 데이터를 생성할 수 있음.   \n",
    "> 이상치 탐지에서는 판별자의 출력 확률을 기반으로 이상치를 식별함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce7b4fcc-fc98-4bc9-830f-a72062bd644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=32):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_gan(generator, discriminator, dataloader, optimizer_G, optimizer_D, criterion, device, num_epochs=50):\n",
    "    \"\"\"\n",
    "    GANs 학습 함수\n",
    "    - generator: 생성자 모델\n",
    "    - discriminator: 판별자 모델\n",
    "    - dataloader: 데이터 로더\n",
    "    - optimizer_G: 생성자 최적화 알고리즘\n",
    "    - optimizer_D: 판별자 최적화 알고리즘\n",
    "    - criterion: 손실 함수 (예: BCELoss)\n",
    "    - device: 학습 디바이스\n",
    "    - num_epochs: 학습 에폭 수\n",
    "    \"\"\"\n",
    "    try:\n",
    "        generator.train()\n",
    "        discriminator.train()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for data in dataloader:\n",
    "                real = data[0].to(device)\n",
    "                batch_size = real.size(0)\n",
    "\n",
    "                # 진짜 데이터 레이블: 1, 가짜 데이터 레이블: 0\n",
    "                real_labels = torch.ones(batch_size, 1).to(device)\n",
    "                fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "                # 생성자 학습\n",
    "                optimizer_G.zero_grad()\n",
    "                z = torch.randn(batch_size, generator.model[0].in_features).to(device)\n",
    "                fake = generator(z)\n",
    "                outputs = discriminator(fake)\n",
    "                loss_G = criterion(outputs, real_labels)\n",
    "                loss_G.backward()\n",
    "                optimizer_G.step()\n",
    "\n",
    "                # 판별자 학습\n",
    "                optimizer_D.zero_grad()\n",
    "                outputs_real = discriminator(real)\n",
    "                loss_D_real = criterion(outputs_real, real_labels)\n",
    "                outputs_fake = discriminator(fake.detach())\n",
    "                loss_D_fake = criterion(outputs_fake, fake_labels)\n",
    "                loss_D = loss_D_real + loss_D_fake\n",
    "                loss_D.backward()\n",
    "                optimizer_D.step()\n",
    "\n",
    "            logger.info(f\"Epoch [{epoch + 1} / {num_epochs}], Loss_D: {loss_D.item():.4f}, Loss_G: {loss_G.item():.4f}\")\n",
    "            \n",
    "        return generator, discriminator\n",
    "    except Exception as e:\n",
    "        logger.error(f\"GANs 학습 중 오류 발생: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def detect_anomalies_gan(generator, discriminator, X, device, threshold=0.5):\n",
    "    \"\"\"\n",
    "    GANs를 사용한 이상치 탐지 함수\n",
    "    - generator: 학습된 생성자 모델\n",
    "    - discriminator: 학습된 판별자 모델\n",
    "    - X: 전체 데이터 (numpy array)\n",
    "    - device: 학습 디바이스\n",
    "    - threshold: 이상치로 간주할 판별자 출력 확률 임계값\n",
    "    \"\"\"\n",
    "    try:\n",
    "        generator.eval()\n",
    "        discriminator.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(X.shape[0], generator.model[0].in_features).to(device)\n",
    "            fake = generator(z)\n",
    "            outputs = discriminator(fake)\n",
    "            # 판별자가 가짜 데이터에 대해 출력한 확률을 이상치 점수로 사용\n",
    "            anomaly_scores = 1 - outputs.cpu().numpy().flatten()\n",
    "        # 임계값을 기준으로 이상치 판별\n",
    "        anomalies = anomaly_scores > threshold\n",
    "        return anomalies, anomaly_score\n",
    "    except Exception as e:\n",
    "        logger.error(f\"GANs를 사용한 이상치 탐지 중 오류 발생: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def train_and_detect_gans(X_train, X_val, X_full, input_dim, latent_dim=32, num_epochs=50, batch_size=1024):\n",
    "    \"\"\"\n",
    "    GANs 모델 학습 및 이상치 탐지 함수\n",
    "    - X_train: 학습 데이터 (numpy array)\n",
    "    - X_val: 검증 데이터 (numpy array)\n",
    "    - X_full: 전체 데이터 (numpy array)\n",
    "    - input_dim: 입력 특징의 차원 수\n",
    "    - latent_dim: 잠재 공간의 차원 수\n",
    "    - num_epochs: 학습 에폭 수\n",
    "    - batch_size: 배치 크기\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"GANs 모델 학습 및 예측 시작\")\n",
    "\n",
    "        #텐서 변환\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "\n",
    "        # DataLoader 생성\n",
    "        train_dataset = TensorDataset(X_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=0)\n",
    "\n",
    "        # 모델 초기화\n",
    "        generator = Generator(input_dim=input_dim, latent_dim=latent_dim).to(device)\n",
    "        discriminator = Discriminator(input_dim=input_dim).to(device)\n",
    "\n",
    "        # 손실 함수 및 최적화 알고리즘 설정\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer_G = optim.Adam(generator.parameters(),\n",
    "                                 lr=1e-3,\n",
    "                                 weight_decay=1e-5)\n",
    "        optimizer_D = optim.Adam(discriminator.parameters(),\n",
    "                                 lr=1e-3,\n",
    "                                 weight_decay=1e-5)\n",
    "\n",
    "        # GAN 학습\n",
    "        generator, discriminator = train_gan(generator,\n",
    "                                             discriminator,\n",
    "                                             train_loader,\n",
    "                                             optimizer_G,\n",
    "                                             optimizer_D,\n",
    "                                             criterion,\n",
    "                                             device,\n",
    "                                             num_epochs=num_epochs)\n",
    "        logger.info(\"GANs 학습 완료\")\n",
    "\n",
    "        # 이상치 탐지\n",
    "        logger.info(\"GANs 기반 이상치 탐지 시작\")\n",
    "        anomalies_gan, anomaly_scores_gan = detect_anomalies_gan(generator,\n",
    "                                                                 discriminator,\n",
    "                                                                 X_full,\n",
    "                                                                 device,\n",
    "                                                                 threshold=0.5)\n",
    "        logger.info(\"GANs 기반 이상치 탐지 완료\")\n",
    "\n",
    "        return anomalies_gan, anomaly_scores_gan\n",
    "    except Exception as e:\n",
    "        logger.info(f\"GANs 학습 및 이상치 탐지 중 오류 발생: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757976e2-d0df-4d03-b3ec-88e2f80e0ff7",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **Generator 및 Discriminator 클래스**: GANs 의 생성자와 판별자를 정의\n",
    "- **train_gan 함수**: GANs 모델을 학습시키는 함수로, 생성자와 판별자를 번갈아가며 학습시킴\n",
    "- **detect_anomalies_gan 함수**: 학습된 GANs를 사용하여 이상치를 탐지. 판별자의 출력 확률을 기반으로 이상치를 식별함\n",
    "- **train_and_detect_gan 함수**: 전체 과정을 통합하여 GANs 모델을 학습시키고 이상치를 탐지함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cbdb00-b5b7-4f05-993d-524d5d97f550",
   "metadata": {},
   "source": [
    "### d. Deep Belief Networks (DBN)\n",
    "\n",
    "> DBN은 여러 개의 Restricted Boltzmann Machines (RBM)으로 구성된 신경망으로, 비지도 학습을 통해 특징을 학습함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e612a90e-3ea1-445e-a995-24a4ed8f9644",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM(nn.Module):\n",
    "    def __init__(self, n_vis, n_hid):\n",
    "        super(RBM, self).__init__()\n",
    "        self.W = nn.Parameter(torch.randn(n_hid, n_vis) * 0.01)\n",
    "        self.h_bias = nn.Parameter(torch.zeros(n_hid))\n",
    "        self.v_bias = nn.Parameter(torch.zeros(n_vis))\n",
    "\n",
    "    def sample_h(self, v):\n",
    "        wx = torch.matmul(v, self.W.t()) + self.h_bias\n",
    "        p_h_given_v = torch.sigmoid(wx)\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "\n",
    "    def sample_v(self, h):\n",
    "        wx = torch.matmul(h, self.W) + self.v_bias\n",
    "        p_v_given_h = torch.sigmoid(wx)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "\n",
    "    def forward(self, v):\n",
    "        p_h, h = self.sample_h(v)\n",
    "        p_v, v = self.sample_v(h)\n",
    "        return v\n",
    "\n",
    "def train_rbm(rbm, train_loader, lr=0.01, k=1, epochs=10):\n",
    "    \"\"\"\n",
    "    RBM 학습 함수\n",
    "    - rbm: RBM 모델\n",
    "    - train_loader: 학습 데이터 로더\n",
    "    - lr: 학습률\n",
    "    - k: Gibbs 샘플링 단계 수\n",
    "    - epochs: 학습 에폭 수\n",
    "    \"\"\"\n",
    "    try:\n",
    "        optimizer = optim.SGD(rbm.parameters(), lr=lr)\n",
    "        for epoch in range(epochs):\n",
    "            loss_ = 0.0\n",
    "            for data in train_loader:\n",
    "                v0 = data[0].to(device)\n",
    "                vk = v0\n",
    "                for _ in range(k):\n",
    "                    p_h, h = rbm.sample_h(vk)\n",
    "                    p_v, vk = rbm.sample_v(h)\n",
    "                loss =  torch.mean((v0 - vk) ** 2)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_ += loss.item()\n",
    "            logger.info(f\"RBM Epoch [{epoch + 1} / {epochs}], Loss: {loss_ / len(train_loader):.6f}\")\n",
    "        return rbm\n",
    "    except Exception as e:\n",
    "        logger.error(f\"RBM 학습 중 오류 발생: {e}\")\n",
    "        return rbm\n",
    "\n",
    "class DBN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(DBN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.layers.append(nn.Linear(layers[i], layers[i + 1]))\n",
    "            self.layers.append(nn.ReLU(True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "def train_dbn_model(X_train, X_val, layers=[128, 64], lr=0.01, epochs=50, batch_size=1024):\n",
    "    \"\"\"\n",
    "    DBN 모델 학습 함수\n",
    "    - X_train: 학습 데이터 (numpy array)\n",
    "    - X_val: 검증 데이터 (numpy array)\n",
    "    - layers: 각 레이어의 노드 수 리스트\n",
    "    - lr: 학습률\n",
    "    - epochs: 학습 에폭 수\n",
    "    - batch_size: 배치 크기\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"DBN 모델 학습 시작\")\n",
    "\n",
    "        # RBM 초기화 및 학습\n",
    "        rbm = RBM(n_vis=X_train.shape[1], n_hid=layers[0]).to(device)\n",
    "        train_loader_rbm = DataLoader(TensorDataset(torch.tensor(X_train, dtype=torch.float32)),\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      num_workers=0)\n",
    "        rbm = train_rbm(rbm, train_loader_rbm, lr=lr, k=1, epochs=10)\n",
    "\n",
    "        # DBN 초기화\n",
    "        dbn = DBN(layers=[X_train.shape[1]] + layers).to(device)\n",
    "        dbn.eval()\n",
    "\n",
    "        # DBN을 사용한 특징 추출 (전이 학습)\n",
    "        with torch.no_grad():\n",
    "            X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "            X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "            X_train_encoded = rbm.encode(X_train_tensor)[0]\n",
    "            X_val_encoded = rbm.encode(X_val_tensor)[0]\n",
    "            X_train_dbn = dbn(X_train_encoded).cpu().numpy()\n",
    "            X_val_dbn = dbn(X_val_encoded).cpu().numpy()\n",
    "\n",
    "        # 이상치 탐지 (재구성 오류 기반)\n",
    "        criterion = nn.MSELoss(reduction='sum')\n",
    "        X_train_tensor_dbn = torch.tensor(X_train_dbn, dtype=torch.float32).to(device)\n",
    "        X_val_tensor_dbn = torch.tensor(X_val_dbn, dtype=torch.float32).to(device)\n",
    "        reconstructed = dbn(X_train_tensor_dbn)\n",
    "        loss = criterion(reconstructed, X_train_tensor_dbn)\n",
    "        logger.info(f\"DBN 재구성 손실: {loss.item():.6f}\")\n",
    "\n",
    "        # 재구성 오류 기반 이상치 탐지\n",
    "        reconstruction_errors_dbn = np.mean((X_train_dbn - dbn(torch.tensor(X_train_dbn, dtype=torch.float32).to(device)).cpu().numpy()) ** 2, axis=1)\n",
    "        threshold = np.percentile(reconstruction_errors_dbn, 99.5)\n",
    "        anomalies_dbn = reconstruction_errors_dbn > threshold\n",
    "        logger.info(\"DBN 기반 이상치 탐지 완료\")\n",
    "\n",
    "        return anomalies_dbn, reconstruction_errors_dbn\n",
    "    except Exception as e:\n",
    "        logger.error(f\"DBN 모델 학습 중 오류 발생: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77459132-7105-4153-8b50-be5804ae1e36",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **RBM 클래스**: Restricted Boltzmann Machine을 정의하며, 인코더와 디코더 역할을 수행함\n",
    "- **train_rbm 함수**: RBM 모델을 학습시키는 함수로, Contrastive Divergence 알고리즘을 사용하여 학습함\n",
    "- **DBN 클래스**: 여러 개의 RBM으로 구성된 Deep Belief Network를 정의함\n",
    "- **train_dbn_model 함수**: DBn 모델을 학습시키고, 재구성 오류를 기반으로 이상치를 탐지함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dc6ccd-7dc9-49cf-809b-db024c2e2b47",
   "metadata": {},
   "source": [
    "### e. LSTM Autoencoder\n",
    "\n",
    "> LSTM Autoencoder는 시계열 데이터의 시간적 패턴을 학습하는 데 특화된 Autoencoder로, 재구성 오류를 기반으로 이상치를 탐지함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c19814d-ccd6-413c-9f0e-d2edda504e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=2, latent_dim=32):\n",
    "        super(LSTM_Autoencoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # 인코더\n",
    "        self.lstm_enc = nn.LSTM(input_dim,\n",
    "                                hidden_dim,\n",
    "                                num_layers,\n",
    "                                batch_first=True)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        # 디코더\n",
    "        self.fc_dec = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.lstm_dec = nn.LSTM(hidden_dim,\n",
    "                                input_dim,\n",
    "                                num_layers,\n",
    "                                batch_first=True)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h, _ = self.lstm_enc(x)\n",
    "        h = h[:, -1, :]  # 마지막 타임스텝의 출력\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, seq_len):\n",
    "        h = self.fc_dec(z).unsqueeze(1).repeat(1, seq_len, 1)\n",
    "        reconstructed, _ = self.lstm_dec(h)\n",
    "        return reconstructed\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        reconstructed = self.decode(z, x.size(1))\n",
    "        return reconstructed, mu, logvar\n",
    "\n",
    "def train_lstm_ae_model(X_train, X_val, X_full, input_dim, hidden_dim=64, num_layers=2, latent_dim=32, num_epochs=50, batch_size=1024):\n",
    "    \"\"\"\n",
    "    LSTM Autoencoder 모델 학습 함수\n",
    "    - X_train: 학습 데이터 (numpy array)\n",
    "    - X_val: 검증 데이터 (numpy array)\n",
    "    - X_full: 전체 데이터 (numpy array)\n",
    "    - input_dim: 입력 특징의 차원 수\n",
    "    - hidden_dim: LSTM의 숨겨진 상태 차원\n",
    "    - num_layers: LSTM 레이어 수\n",
    "    - latent_dim: 잠재 공간의 차원 수\n",
    "    - num_epochs: 학습 에폭 수\n",
    "    - batch_size: 배치 크기\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"LSTM Autoencoder 모델 학습 시작\")\n",
    "\n",
    "        # 텐서 변환\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "\n",
    "        # DataLoader 생성\n",
    "        train_dataset = TensorDataset(X_train_tensor)\n",
    "        val_dataset = TensorDataset(X_val_tensor)\n",
    "        train_loader = DataLoader(train_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=0)\n",
    "        val_loader = DataLoader(val_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                num_workers=0)\n",
    "\n",
    "        # 모델 초기화\n",
    "        lstm_ae = LSTM_Autoencoder(input_dim=input_dim,\n",
    "                                   hidden_dim=hidden_dim,\n",
    "                                   num_layers=num_layers,\n",
    "                                   latent_dim=latent_dim).to(device)\n",
    "        criterion = nn.MSELoss(reduction='sum')\n",
    "        optimizer = optim.Adam(lstm_ae.parameters(),\n",
    "                               lr=1e-3,\n",
    "                               weight_decay=1e-5)\n",
    "\n",
    "        best_val_loss = np.inf\n",
    "        for epoch in range(num_epochs):\n",
    "            lstm_ae.train()\n",
    "            running_loss = 0.0\n",
    "            for data in train_loader:\n",
    "                inputs = data[0].to(device)\n",
    "                reconstructed, mu, logvar = lstm_ae(inputs)\n",
    "                recon_loss = criterion(reconstructed, inputs)\n",
    "                kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "                loss = recon_loss + kl_loss\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "            epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "            # 검증\n",
    "            lstm_ae.eval()\n",
    "            running_val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    inputs = data[0].to(device)\n",
    "                    reconstructed, mu, logvar = lstm_ae(inputs)\n",
    "                    recon_loss = criterion(reconstructed, inputs)\n",
    "                    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "                    loss = recon_loss + kl_loss\n",
    "                    running_val_loss += loss.item()\n",
    "            epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "\n",
    "            logger.info(f\"Epoch [{epoch + 1} / {num_epochs}], Train_Loss: {epoch_train_loss:.6f}, Val_Loss: {epoch_val_loss:.6f}\")\n",
    "\n",
    "            # 최적 모델 저장\n",
    "            if epoch_val_loss < best_val_loss:\n",
    "                best_val_loss = epoch_val_loss\n",
    "                torch.save(lstm_ae.state_dict(), './Models/lstm_ae.pth')\n",
    "                logger.info(f\"최적 LSTM Autoencoder 모델 저장 (Epoch {epoch + 1})\")\n",
    "\n",
    "        # 학습 완료 후 최적 모델 로드\n",
    "        lstm_ae.load_state_dict(torch.load('./Models/lstm_ae.pth'))\n",
    "        lstm_ae.eval()\n",
    "        logger.info(\"LSTM Autoencoder 모델 학습 완료 및 최적 모델 로드\")\n",
    "\n",
    "        # 재구성 오류 계산\n",
    "        reconstruction_errors = []\n",
    "        data_loader_full = DataLoader(TensorDataset(torch.tensor(X_full, dtype=torch.float32)),\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=False,\n",
    "                                      num_workers=0)\n",
    "        logger.info(\"LSTM Autoencoder를 사용한 재구성 오류 계산 시작\")\n",
    "        for data in tqdm(data_loader_full, desc=\"LSTM AE Reconstruction Error\"):\n",
    "            inputs = data[0].to(device)\n",
    "            with torch.no_grad():\n",
    "                reconstructed, mu, logvar = lstm_ae(inputs)\n",
    "                loss = torch.mean((reconstructed - inputs) ** 2, dim=(1, 2))  # 샘플별 MSE\n",
    "                reconstruction_errors.extend(loss.cpu().numpy())\n",
    "\n",
    "        # 재구성 오류 기반 이상치 탐지\n",
    "        threshold = np.percentile(reconstruction_errors, 99.5)  # 상위 0.5%를 이상치로 간주\n",
    "        anomalies = np.array(reconstruction_errors) > threshold\n",
    "        logger.info(\"LSTM Autoencoder 기반 이상치 탐지 완료\")\n",
    "\n",
    "        return anomalies, reconstruction_errors\n",
    "    except Exception as e:\n",
    "        logger.error(f\"LSTM Autoencoder 모델 학습 중 오류 발생: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9f9aa6-37f8-411b-a5fc-a19815bc3371",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **LSTM_Autoencoder 클래스**: LSTM을 인코더와 디코더로 사용하여 시계열 데이터를 학습함\n",
    "- **train_lstm_ae_model 함수**: LSTM Autoencoder 모델을 학습시키고, 재구성 오류를 기반으로 이상치를 탐지함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d5cb20-6fd3-49f4-a5f1-d25ca2b50210",
   "metadata": {},
   "source": [
    "### f. Transformer Autoencoder\n",
    "\n",
    "> Transformer 기반 Autoencoder는 시계열 데이터의 장기적인 의존성을 학습하는 데 유리한 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79167583-edb4-4ba9-a137-e57dbe88af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, seq_length, nhead=8, num_layers=3, dim_feedforward=512, latent_dim=32):\n",
    "        super(Transformer_Autoencoder, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=input_dim,\n",
    "                                                        nhead=nhead,\n",
    "                                                        dim_feedforward=dim_feedforward)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer,\n",
    "                                                         num_layers=num_layers)\n",
    "        self.fc_mu = nn.Linear(input_dim * seq_length, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(input_dim * seq_length, latent_dim)\n",
    "        self.fc_dec = nn.Linear(latent_dim, input_dim * seq_length)\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=input_dim,\n",
    "                                                        nhead=nhead,\n",
    "                                                        dim_feedforward=dim_feed_forward)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(self.decoder_layer,\n",
    "                                                         num_layers=num_layers)\n",
    "\n",
    "    def encode(self, x):\n",
    "        # x: (batch, seq_length, input_dim)\n",
    "        x = x.permute(1, 0, 2)  # (seq_length, batch, input_dim)\n",
    "        encoded = self.transformer_encoder(x)  # (seq_length, batch, input_dim)\n",
    "        encoded = encoded.permute(1, 0, 2).contiguous().view(x.size(1), -1)  # (batch, seq_length * input_dim)\n",
    "        mu = self.fc_mu(encoded)\n",
    "        logvar = self.fc_logvar(encoded)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        decoded = self.fc_dec(z)  # (batch, seq_length * input_dim)\n",
    "        decoded = decoded.view(-1, self.seq_length, self.input_dim)  # (batch, seq_length, input_dim)\n",
    "        decoded = decoded.permute(1, 0, 2)  # (seq_length, batch, input_dim)\n",
    "        decoded = self.transformer_decoder(decoded, memory=None)  # (seq_length, batch, input_dim)\n",
    "        decoded = decoded.permute(1, 0, 2).contiguous()  # (batch, seq_length, input_dim)\n",
    "        return decoded\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        reconstructed = self.decode(z)\n",
    "        return reconstructed, mu, logvar\n",
    "\n",
    "def train_transformer_ae_model(X_train, X_val, X_full, input_dim, seq_length, nhead=8, num_layers=3, dim_feedforward=512, latent_dim=32, num_epochs=50, batch_size=1024):\n",
    "    \"\"\"\n",
    "    Transformer Autoencoder 모델 학습 함수\n",
    "    - X_train: 학습 데이터 (numpy array)\n",
    "    - X_val: 검증 데이터 (numpy array)\n",
    "    - X_full: 전체 데이터 (numpy array)\n",
    "    - input_dim: 입력 특징의 차원 수\n",
    "    - seq_length: 시계열 길이\n",
    "    - nhead: Multi-Head Attention의 헤드 수\n",
    "    - num_layers: Transformer 레이어 수\n",
    "    - dim_feedforward: Feedforward 신경망의 차원 수\n",
    "    - latent_dim: 잠재 공간의 차원 수\n",
    "    - num_epochs: 학습 에폭 수\n",
    "    - batch_size: 배치 크기\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"Transformer Autoencoder 모델 학습 시작\")\n",
    "\n",
    "        # 텐서 변환 및 시퀸스 길이 맞추기\n",
    "        X_train_seq = X_train.reshape(-1,\n",
    "                                      seq_length,\n",
    "                                      input_dim)\n",
    "        X_val_seq = X_val.reshape(-1,\n",
    "                                  seq_length,\n",
    "                                  input_dim)\n",
    "        X_full_seq = X_full.reshape(-1,\n",
    "                                    seq_length,\n",
    "                                    input_dim)\n",
    "\n",
    "        X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val_seq, dtype=torch.float32)\n",
    "\n",
    "        # DataLoader 생성\n",
    "        train_dataset = TensorDataset(X_train_tensor)\n",
    "        val_dataset = TensorDataset(X_val_tensor)\n",
    "        train_loader = DataLoader(train_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=0)\n",
    "        val_loader = DataLoader(val_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                num_workers=0)\n",
    "\n",
    "        # 모델 초기화\n",
    "        transformer_ae = Transformer_Autoencoder(input_dim=input_dim,\n",
    "                                                 seq_length=seq_length,\n",
    "                                                 num_layers=num_layers,\n",
    "                                                 dim_feedforward=dim_feedforward,\n",
    "                                                 latent_dim=latent_dim).to(device)\n",
    "        criterion = nn.MSELoss(reduction='sum')\n",
    "        optimizer = optim.Adam(transformer_ae.parameters(),\n",
    "                               lr=1e-3,\n",
    "                               weight_decay=1e-5)\n",
    "\n",
    "        best_val_loss = np.inf\n",
    "        for epoch in range(num_epochs):\n",
    "            transformer_ae.train()\n",
    "            running_loss = 0.0\n",
    "            for data in train_loader:\n",
    "                inputs = data[0].to(device)\n",
    "                reconstructed, mu, logvar = transformer_ae(inputs)\n",
    "                recon_loss = criterion(reconstructed, inputs)\n",
    "                kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "                loss = recon_loss + kl_loss\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "            epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "            # 검증\n",
    "            transformer_ae.eval()\n",
    "            running_val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    inputs = data[0].to(device)\n",
    "                    reconstructed, mu, logvar = transformer_ae(inputs)\n",
    "                    recon_loss = criterion(reconstructed, inputs)\n",
    "                    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "                    loss = recon_loss + kl_loss\n",
    "                    running_val_loss += loss.item()\n",
    "            epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "\n",
    "            logger.info(f\"Epoch [{epoch + 1} / {num_epochs}], Train_Loss: {epoch_train_loss:.6f}, Val_Loss: {epoch_val_loss:.6f}\")\n",
    "\n",
    "            # 최적 모델 저장\n",
    "            if epoch_val_loss < best_val_loss:\n",
    "                best_val_loss = epoch_val_loss\n",
    "                torch.save(transformer_ae.state_dict(), './Models/transformer_ae.pth')\n",
    "                logger.info(f\"최적 Transformer Autoencoder 모델 저장 (Epoch {epoch + 1})\")\n",
    "\n",
    "        # 학습 완료 후 최적 모델 로드\n",
    "        transformer_ae.load_state_dict(torch.load('./Models/transformer_ae.pth'))\n",
    "        transformer_ae.eval()\n",
    "        logger.info(\"Transformer Autoencoder 모델 학습 완료 및 최적 모델 로드\")\n",
    "\n",
    "        # 재구성 오류 계산\n",
    "        reconstruction_errors = []\n",
    "        data_loader_full = DataLoader(TensorDataset(torch.tensor(X_full_seq, dtype=torch.float32)),\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=False,\n",
    "                                      num_workers=0)\n",
    "        logger.info(\"Transformer Autoencoder를 사용한 재구성 오류 계산 시작\")\n",
    "        for data in tqdm(data_loader_full, desc=\"Transformer AE Reconstruction Error\"):\n",
    "            inputs = data[0].to(device)\n",
    "            with torch.no_grad():\n",
    "                reconstructed, mu, logvar = transformer_ae(inputs)\n",
    "                loss = torch.mean((reconstructed - inputs) ** 2, dim=(1, 2))  # 샘플별 MSE\n",
    "                reconstruction_errors.extend(loss.cpu().numpy())\n",
    "\n",
    "        # 재구성 오류 기반 이상치 탐지\n",
    "        threshold = np.percentile(reconstruction_errors, 99.5)  # 상위 0.5%를 이상치로 간주\n",
    "        anomalies = np.array(reconstruction_errors) > threshold\n",
    "        logger.info(\"Transformer Autoencoder 기반 이상치 탐지 완료\")\n",
    "\n",
    "        return anomalies, reconstruction_errors\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Transformer Autoencoder 모델 학습 중 오류 발생: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e0101f-3b3a-4de7-b044-c304ab21cc78",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **Transformer_Autoencoder 클래스**: Transformer 인코더와 디코더를 사용하여 시계열 데이터를 학습함\n",
    "- **train_transformer_ae_model 함수**: Transformer Autoencoder 모델을 학습시키고, 재구성 오류를 기반으로 이상치를 탐지함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2187f6-1933-4fd7-b3f8-402d06ea1031",
   "metadata": {},
   "source": [
    "***\n",
    "## 8. 앙상블 방법: Majority Voting\n",
    "\n",
    "> 여러 모델의 예측을 결합하여 최종 이상치를 판별하기 위해 앙상블 방법 중 **Majority Voting**을 도입.   \n",
    "> 이는 비지도 학습 모델의 예측 결과를 통합하여 보다 신뢰성 있는 이상치 탐지를 가능하게 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e456cd5f-6450-4841-b082-eff60d2aa8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting(anomalies_list, threshold=3):\n",
    "    \"\"\"\n",
    "    Majority Voting을 사용하여 앙상블을 수행함.\n",
    "    - anomalies_list: 각 모델의 이상치 예측 결과 리스트 (numpy array)\n",
    "    - threshold: 이상치로 간주할 최소 모델 수\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"Majority Voting을 사용한 앙상블 시작\")\n",
    "        # 각 모델의 이상치 예측을 합산\n",
    "        combined = np.sum(anomalies_list, axis=0)\n",
    "        # threshold 이상일 때 이상치로 판별\n",
    "        final_anomalies = combined >= threshold\n",
    "        logger.info(\"Majority Voting 앙상블 완료\")\n",
    "        return final_anomalies\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Majority Voting 앙상블 중 오류 발생: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efed897f-3a47-4ee6-b6bc-eaa7f7f7c538",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **anomalies_list**: 각 모델이 예측한 이상치의 리스트를 전달함\n",
    "- **threshold**: 여러 모델 중 최소 몇 개의 모델이 이상치로 예측해야 최종적으로 이상치로 판별할 지를 설정함\n",
    "- **최종 이상치 판별**: 각 샘플에 대해 이상치로 예측한 모델의 수가 threshold 이상인 경우 이상치로 판별함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184f4b31-c541-484f-8fb4-bf4b5cf433bb",
   "metadata": {},
   "source": [
    "***\n",
    "## 9. 모델 평가\n",
    "\n",
    "> 모델의 성능을 평가하기 위해 다양한 지표를 계산함.   \n",
    "> 여기서는 Silhouette Score와 같은 클러스터링 지표를 사용하여 모델의 품질을 평가함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d160a7b-9235-4ce6-8f98-555c51f2b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(anomalies, X):\n",
    "    \"\"\"\n",
    "    모델 평가 지표를 계산함.\n",
    "    - anomalies: 이상치 예측 결과 (numpy array)\n",
    "    - X: 입력 데이터 (numpy array)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"모델 평가 지표 계산 시작\")\n",
    "\n",
    "        # 클러스터링을 위한 라벨 생성 (0: 정상, 1: 이상치)\n",
    "        labels = anomalies.astype(int)\n",
    "\n",
    "        # Silhouette Score 계산\n",
    "        if len(set(labels)) > 1:\n",
    "            silhouette = silhouette_score(X, labels)\n",
    "            davies_bouldin = davies_bouldin_score(X, labels)\n",
    "            calinski_harabasz = calinski_harabasz_score(X, labels)\n",
    "        else:\n",
    "            silhouette = -1\n",
    "            davies_bouldin = -1\n",
    "            calinski_harabasz = -1\n",
    "\n",
    "        evaluation_metrics = {\n",
    "            'Silhouette Score': silhouette,\n",
    "            'Davies-Bouldin Score': davies_bouldin,\n",
    "            'Calinski-Harabasz Score': calinski_harabasz\n",
    "        }\n",
    "\n",
    "        logger.info(f\"Silhouette Score: {silhouette}\")\n",
    "        logger.info(f\"Davies-Bouldin Score: {davies_bouldin}\")\n",
    "        logger.info(f\"Calinski-Harabasz Score: {calinski_harabasz}\")\n",
    "\n",
    "        return evaluation_metrics\n",
    "    except Exception as e:\n",
    "        logger.error(f\"모델 평가 지표 계산 중 오류 발생: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be219f19-8c67-4476-8def-65c4f2bf22b7",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **Silhouette Score**: 클러스터의 응집도와 분리도를 평가하는 지표로, 1에 가까울수록 좋은 클러스터링을 의미함\n",
    "- **Davies-Bouldin Score**: 클러스터 간의 분리를 평가하는 지표로, 값이 낮을수록 좋은 클러스터링을 의미함\n",
    "- **Calinski-Harabasz Score**: 클러스터 내 응집도와 클러스터 간 분리를 평가하는 지표로, 값이 높을수록 좋은 클러스터링을 의미함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de11c584-9bac-43ad-8f7b-466bf1fe7efa",
   "metadata": {},
   "source": [
    "***\n",
    "## 10.모델 해석 및 투명성 강화\n",
    "\n",
    "> 모델의 예측을 해석하고, 이상치 탐지의 원인을 설명할 수 있도록 **SHAP**과 **LIME**을 활용하여 모델의 투명성을 강화함\n",
    "\n",
    "### a. SHAP를 사용한 모델 해석\n",
    "> **SHAP**(SHapley Additive exPlanations)는 모델의 예측에 기여한 각 특징의 중요도를 시각화하는 도구임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192fd81b-aa1d-47c5-a076-e49d0612e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_model_shap(model, X, feature_names):\n",
    "    \"\"\"\n",
    "    SHAP를 사용하여 모델 해석\n",
    "    - model: 학습된 모델\n",
    "    - X: 특징 데이터 (numpy array 또는 pandas DataFrame)\n",
    "    - feature_names: 특징 이름 리스트\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"SHAP를 사용한 모델 해석 시작\")\n",
    "        explainer = shap.Explainer(model, X)\n",
    "        shap_values = explainer(X)\n",
    "        shap.summary_plot(shap_values, features=X, feature_names=feature_names)\n",
    "        logger.info(\"SHAP 모델 해석 완료\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"SHAP 모델 해석 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cf131f-6000-4a75-9641-8a7be6e70ab9",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **Explainer 생성**: 모델과 데이터를 기반으로 SHAP Explainer를 생성함.\n",
    "- **Shap Values 계산**: 각 샘플에 대한 Shapley 값을 계산함.\n",
    "- **시각화**: SHAP summary plot을 통해 특징의 중요도를 시각화함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d32283-745b-4aa0-80c7-a3e6a1f11bd6",
   "metadata": {},
   "source": [
    "### b. LIME을 사용한 모델 해석\n",
    "> **LIME**(Local Interpretable Model-agnostic Explanations)은 특정 샘플에 대한 모델의 예측을 해석하는 도구임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f47455-b42f-4c2b-a71f-d8a51e73c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_model_lime(model, X, feature_names, num_features=10):\n",
    "    \"\"\"\n",
    "    LIME을 사용하여 모델 해석\n",
    "    - model: 학습된 모델\n",
    "    - X: 특징 데이터 (numpy array)\n",
    "    - feature_names: 특징 이름 리스트\n",
    "    - nu_features: 해석할 특징 수\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"LIME을 사용한 모델 해석 시작\")\n",
    "        explainer = lime_tabular.LimeTabularExplainer(\n",
    "            training_data = X,\n",
    "            feature_names = feature_names,\n",
    "            mode = 'classification',\n",
    "            discretize_continuous=True\n",
    "        )\n",
    "        # 예시로 첫 번째 샘플을 해석\n",
    "        i = 0\n",
    "        exp = explainer.explain_instance(X[i],\n",
    "                                         model.predict_proba,\n",
    "                                         num_features=num_features)\n",
    "        exp.show_in_notebook(show_table=True)\n",
    "        logger.info(\"LIME 모델 해석 완료\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"LIME 모델 해석 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c4e9c6-efe8-4c04-83cd-0786ffa7912c",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **Explainer 생성**: LIME Explainer를 생성하여 모델의 로컬 해석을 준비함.\n",
    "- **설명 생성**: 특정 샘플에 대한 모델의 예측을 해석함.\n",
    "- **시각화**: LIME explanation을 통해 주요 특징의 기여도를 시각화함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc0a996-8881-426d-8414-5f4eceadc0fa",
   "metadata": {},
   "source": [
    "***\n",
    "## 11. 모델 최적화 및 경량화\n",
    "\n",
    "> 모델의 추론 속도를 최적화하고, 리소스 효율적인 모델로 경량화하기 위해 **ONNX**와 **TensorRT**를 사용함.\n",
    "\n",
    "### a. PyTorch 모델을 ONNX로 변환\n",
    "\n",
    "> ONNX(Open Neural Network Exchange)는 다양한 딥러닝 프레임워크 간의 모델 호환성을 제공함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55bedd8-02c8-4e32-b0ca-13f04d5ad604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_onnx(model, input_sample, model_name='model'):\n",
    "    \"\"\"\n",
    "    PyTorch 모델을 ONNX 형식으로 변환함.\n",
    "    - model: 학습된 PyTorch 모델\n",
    "    - input_sample: 모델에 대한 입력 샘플 (numpy array 또는 torch tensor)\n",
    "    - model_name: 저장할 ONNX 모델 파일 이름\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"모델을 ONNX 형식으로 변환 시작: {model_name}.onnx\")\n",
    "        model.eval()\n",
    "        if isinstance(input_sample, np.ndarray):\n",
    "            input_sample = torch.from_numpy(input_sample).float()\n",
    "        torch.onnx.export(model, input_sample, f\"{model_name}.onnx\",\n",
    "                          export_params=True,\n",
    "                          opset_version=12,\n",
    "                          do_constant_folding=True,\n",
    "                          input_names=['input'],\n",
    "                          output_names=['output'],\n",
    "                          dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n",
    "        logger.info(f\"모델을 ONNX 형식으로 변환 완료: {model_name}.onnx\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"모델을 ONNX 형식으로 변환 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4250cd-8d3b-48b6-b42a-ce998bb3992d",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **모델 변환**: PyTorch 모델을 ONNX 형식으로 변환하여 다양한 플랫폼에서 사용할 수 있게 함.\n",
    "- **입력 샘플**: 변환 과정에서 필요한 입력 샘플을 제공하여 모델의 구조를 정의함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988cb7aa-09fe-4851-8d6a-2358e1769fcf",
   "metadata": {},
   "source": [
    "### b. TensorRT를 사용한 모델 최적화\n",
    "> TensorRT는 NVIDIA GPU에서 딥러닝 모델의 추론 속도를 최적화하는 도구."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1764e0-2a65-4a90-9bb2-80a9380ddfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model_with_tensrrt(onnx_model_path, trt_model_path):\n",
    "    \"\"\"\n",
    "    TensorRT를 사용하여 ONNX 모델을 최적화함.\n",
    "    - onnx_model_path: 변화된 ONNX 모델 파일 경로\n",
    "    - trt_model_path: 최적화된 TensorRT 모델 파일 경로\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"TensorRT를 사용한 모델 최적화 시작: {onnx_model_path} -> {trt_model_path}\")\n",
    "        TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "        builder = trt.Builder(TRT_LOGGER)\n",
    "        network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "        parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "\n",
    "        with open(onnx_model_path, 'rb') as model:\n",
    "            if not parser.parse(model.read()):\n",
    "                for error in range(parser.num_errors):\n",
    "                    logger.error(parser.get_error(error))\n",
    "                return False\n",
    "\n",
    "        builder.max_workspace_size = 1 << 30  # 1GB\n",
    "        builder.max_batch_size = 1\n",
    "        engine = builder.build_cuda_engine(network)\n",
    "\n",
    "        with open(trt_model_path, 'wb') as f:\n",
    "            f.write(engine.serialize())\n",
    "\n",
    "        logger.info(f\"TensorRT를 사용한 모델 최적화 완료: {trt_model_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"TensorRT를 사용한 모델 최적화 중 오류 발생: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be33d95-828f-4d92-954d-79eb65679127",
   "metadata": {},
   "source": [
    "### 설명:\n",
    "- **TensorRT 최적화**: ONNX 모델을 TensorRT 엔진으로 변환하여 NVIDIA GPU에서의 추론 속도를 향상시킴.\n",
    "- **설정**: 최대 워크스페이스 크기 및 배치 크기를 설정하여 최적화를 수행함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413fb6da-fd63-486e-8cdd-ffe499caad23",
   "metadata": {},
   "source": [
    "***\n",
    "## 12. 파이프라인 자동화: Airflow 활용\n",
    "\n",
    "> 전체 파이프라인의 데이터 처리, 모델 학습, 평가, 배포 단계를 자동화하기 위해 **Apache Airflow**를 활용함.   \n",
    "> Airflow는 워크플로우를 DAG(Directed Acyclic Graph) 형태로 정의하고, 각 작업을 스케줄링하며 관리할 수 있음."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
